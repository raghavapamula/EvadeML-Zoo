{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import pdb\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import app\n",
    "from tensorflow.python.platform import flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The first part is just the same as main.py from the EvadeML repo\n",
    "    * I need adverserial examples to run my tests, so I'm using the pre-written code to generate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_string('dataset_name', 'MNIST', 'Supported: MNIST, CIFAR-10, ImageNet.')\n",
    "flags.DEFINE_integer('nb_examples', 5, 'The number of examples selected for attacks.')\n",
    "flags.DEFINE_boolean('test_mode', False, 'Only select one sample for each class.')\n",
    "flags.DEFINE_string('model_name', 'cleverhans', 'Supported: cleverhans, cleverhans_adv_trained and carlini for MNIST; carlini and DenseNet for CIFAR-10;  ResNet50, VGG19, Inceptionv3 and MobileNet for ImageNet.')\n",
    "flags.DEFINE_string('attacks', \"FGSM?eps=0.1;BIM?eps=0.1&eps_iter=0.02;JSMA?targeted=next;CarliniL2?targeted=next&batch_size=100&max_iterations=1000;CarliniL2?targeted=next&batch_size=100&max_iterations=1000&confidence=2\", 'Attack name and parameters in URL style, separated by semicolon.')\n",
    "flags.DEFINE_boolean('visualize', True, 'Output the image examples for each attack, enabled by default.')\n",
    "flags.DEFINE_string('defense', 'feature_squeezing1', 'Supported: feature_squeezing.')\n",
    "flags.DEFINE_string('detection', 'feature_squeezing1', 'Supported: feature_squeezing.')\n",
    "flags.DEFINE_string('result_folder', \"results\", 'The output folder for results.')\n",
    "flags.DEFINE_boolean('verbose', False, 'Stdout level. The hidden content will be saved to log files anyway.')\n",
    "\n",
    "FLAGS.model_name = FLAGS.model_name.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tf_session():\n",
    "    # Set TF random seed to improve reproducibility\n",
    "    tf.set_random_seed(1234)\n",
    "\n",
    "    # Create TF session and set as Keras backend session\n",
    "    sess = tf.Session()\n",
    "    keras.backend.set_session(sess)\n",
    "    print(\"Created TensorFlow session and set Keras backend.\")\n",
    "    return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Located Cleverhans\n",
      "Located Carlini_nn_robust_attacks\n",
      "Located Keras-deep-learning-models\n",
      "Located MobileNets\n",
      "Located Deepfool/Universal\n",
      "Located DenseNet\n"
     ]
    }
   ],
   "source": [
    "# 0. Select a dataset.\n",
    "from datasets import MNISTDataset, CIFAR10Dataset, ImageNetDataset\n",
    "from datasets import get_correct_prediction_idx, evaluate_adversarial_examples, calculate_mean_confidence, calculate_accuracy\n",
    "\n",
    "if FLAGS.dataset_name == \"MNIST\":\n",
    "    dataset = MNISTDataset()\n",
    "elif FLAGS.dataset_name == \"CIFAR-10\":\n",
    "    dataset = CIFAR10Dataset()\n",
    "elif FLAGS.dataset_name == \"ImageNet\":\n",
    "    dataset = ImageNetDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===Loading MNIST data...\n"
     ]
    }
   ],
   "source": [
    "# 1. Load a dataset.\n",
    "print (\"\\n===Loading %s data...\" % FLAGS.dataset_name)\n",
    "if FLAGS.dataset_name == 'ImageNet':\n",
    "    if FLAGS.model_name == 'inceptionv3':\n",
    "        img_size = 299\n",
    "    else:\n",
    "        img_size = 224\n",
    "    X_test_all, Y_test_all = dataset.get_test_data(img_size, 0, 200)\n",
    "else:\n",
    "    X_test_all, Y_test_all = dataset.get_test_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created TensorFlow session and set Keras backend.\n",
      "\n",
      "===Defined TensorFlow model graph.\n",
      "---Loaded MNIST-cleverhans model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Load a trained model.\n",
    "sess = load_tf_session()\n",
    "keras.backend.set_learning_phase(0)\n",
    "# Define input TF placeholder\n",
    "x = tf.placeholder(tf.float32, shape=(None, dataset.image_size, dataset.image_size, dataset.num_channels))\n",
    "y = tf.placeholder(tf.float32, shape=(None, dataset.num_classes))\n",
    "\n",
    "with tf.variable_scope(FLAGS.model_name):\n",
    "    \"\"\"\n",
    "    Create a model instance for prediction.\n",
    "    The scaling argument, 'input_range_type': {1: [0,1], 2:[-0.5, 0.5], 3:[-1, 1]...}\n",
    "    \"\"\"\n",
    "    model = dataset.load_model_by_name(FLAGS.model_name, logits=False, input_range_type=1)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='sgd', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the pre-trained model...\n",
      "Test accuracy on raw legitimate examples 0.9919\n",
      "Mean confidence on ground truth classes 0.8897\n"
     ]
    }
   ],
   "source": [
    "# 3. Evaluate the trained model.\n",
    "# TODO: add top-5 accuracy for ImageNet.\n",
    "print (\"Evaluating the pre-trained model...\")\n",
    "Y_pred_all = model.predict(X_test_all)\n",
    "mean_conf_all = calculate_mean_confidence(Y_pred_all, Y_test_all)\n",
    "accuracy_all = calculate_accuracy(Y_pred_all, Y_test_all)\n",
    "print('Test accuracy on raw legitimate examples %.4f' % (accuracy_all))\n",
    "print('Mean confidence on ground truth classes %.4f' % (mean_conf_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 5 examples.\n",
      "Selected index in test set (sorted): 0-4:1\n",
      "Test accuracy on selected legitimate examples 1.0000\n",
      "Mean confidence on ground truth classes, selected 0.9180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Select some examples to attack.\n",
    "import hashlib\n",
    "from datasets import get_first_example_id_each_class\n",
    "# Filter out the misclassified examples.\n",
    "correct_idx = get_correct_prediction_idx(Y_pred_all, Y_test_all)\n",
    "if FLAGS.test_mode:\n",
    "    # Only select the first example of each class.\n",
    "    correct_and_selected_idx = get_first_example_id_each_class(Y_test_all[correct_idx])\n",
    "    selected_idx = [ correct_idx[i] for i in correct_and_selected_idx ]\n",
    "else:\n",
    "    selected_idx = correct_idx[:FLAGS.nb_examples]\n",
    "\n",
    "from utils.output import format_number_range\n",
    "selected_example_idx_ranges = format_number_range(sorted(selected_idx))\n",
    "print ( \"Selected %d examples.\" % len(selected_idx))\n",
    "print ( \"Selected index in test set (sorted): %s\" % selected_example_idx_ranges )\n",
    "\n",
    "X_test, Y_test, Y_pred = X_test_all[selected_idx], Y_test_all[selected_idx], Y_pred_all[selected_idx]\n",
    "\n",
    "accuracy_selected = calculate_accuracy(Y_pred, Y_test)\n",
    "mean_conf_selected = calculate_mean_confidence(Y_pred, Y_test)\n",
    "print('Test accuracy on selected legitimate examples %.4f' % (accuracy_selected))\n",
    "print('Mean confidence on ground truth classes, selected %.4f\\n' % (mean_conf_selected))\n",
    "\n",
    "task = {}\n",
    "task['dataset_name'] = FLAGS.dataset_name\n",
    "task['model_name'] = FLAGS.model_name\n",
    "task['accuracy_test'] = accuracy_all\n",
    "task['mean_confidence_test'] = mean_conf_all\n",
    "\n",
    "task['test_set_selected_length'] = len(selected_idx)\n",
    "task['test_set_selected_idx_ranges'] = selected_example_idx_ranges\n",
    "task['test_set_selected_idx_hash'] = hashlib.sha1(str(selected_idx).encode('utf-8')).hexdigest()\n",
    "task['accuracy_test_selected'] = accuracy_selected\n",
    "task['mean_confidence_test_selected'] = mean_conf_selected\n",
    "\n",
    "task_id = \"%s_%d_%s_%s\" % \\\n",
    "        (task['dataset_name'], task['test_set_selected_length'], task['test_set_selected_idx_hash'][:5], task['model_name'])\n",
    "\n",
    "FLAGS.result_folder = os.path.join(FLAGS.result_folder, task_id)\n",
    "if not os.path.isdir(FLAGS.result_folder):\n",
    "    os.makedirs(FLAGS.result_folder)\n",
    "\n",
    "from utils.output import save_task_descriptor\n",
    "save_task_descriptor(FLAGS.result_folder, [task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running attack: fgsm {'eps': 0.1}\n",
      "Loading adversarial examples from [MNIST_5_930c7_cleverhans_fgsm?eps=0.1.pickle].\n",
      "{'duration': 0.37016987800598145}\n",
      "\n",
      "Running attack: bim {'eps': 0.1, 'eps_iter': 0.02}\n",
      "Loading adversarial examples from [MNIST_5_930c7_cleverhans_bim?eps=0.1&eps_iter=0.02.pickle].\n",
      "{'duration': 2.0183029174804688}\n",
      "\n",
      "Running attack: jsma {'targeted': 'next'}\n",
      "Loading adversarial examples from [MNIST_5_930c7_cleverhans_jsma?targeted=next.pickle].\n",
      "{'duration': 3.0805959701538086}\n",
      "\n",
      "Running attack: carlinil2 {'targeted': 'next', 'batch_size': 100, 'max_iterations': 1000}\n",
      "Loading adversarial examples from [MNIST_5_930c7_cleverhans_carlinil2?targeted=next&batch_size=100&max_iterations=1000.pickle].\n",
      "{'duration': 84.23960661888123}\n",
      "\n",
      "Running attack: carlinil2 {'targeted': 'next', 'batch_size': 100, 'max_iterations': 1000, 'confidence': 2.0}\n",
      "Loading adversarial examples from [MNIST_5_930c7_cleverhans_carlinil2?targeted=next&batch_size=100&max_iterations=1000&confidence=2.pickle].\n",
      "{'duration': 84.89094090461731}\n"
     ]
    }
   ],
   "source": [
    "# 5. Generate adversarial examples.\n",
    "from attacks import maybe_generate_adv_examples, parse_attack_string\n",
    "from defenses.feature_squeezing.squeeze import reduce_precision_np\n",
    "attack_string_hash = hashlib.sha1(FLAGS.attacks.encode('utf-8')).hexdigest()[:5]\n",
    "sample_string_hash = task['test_set_selected_idx_hash'][:5]\n",
    "\n",
    "from attacks import get_next_class, get_least_likely_class\n",
    "Y_test_target_next = get_next_class(Y_test)\n",
    "Y_test_target_ll = get_least_likely_class(Y_pred)\n",
    "\n",
    "X_test_adv_list = []\n",
    "\n",
    "attack_string_list = filter(lambda x:len(x)>0, FLAGS.attacks.lower().split(';'))\n",
    "to_csv = []\n",
    "\n",
    "X_adv_cache_folder = os.path.join(FLAGS.result_folder, 'adv_examples')\n",
    "adv_log_folder = os.path.join(FLAGS.result_folder, 'adv_logs')\n",
    "predictions_folder = os.path.join(FLAGS.result_folder, 'predictions')\n",
    "for folder in [X_adv_cache_folder, adv_log_folder, predictions_folder]:\n",
    "    if not os.path.isdir(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "predictions_fpath = os.path.join(predictions_folder, \"legitimate.npy\")\n",
    "np.save(predictions_fpath, Y_pred, allow_pickle=False)\n",
    "\n",
    "for attack_string in attack_string_list:\n",
    "    attack_log_fpath = os.path.join(adv_log_folder, \"%s_%s.log\" % (task_id, attack_string))\n",
    "    attack_name, attack_params = parse_attack_string(attack_string)\n",
    "    print ( \"\\nRunning attack: %s %s\" % (attack_name, attack_params))\n",
    "\n",
    "    if 'targeted' in attack_params:\n",
    "        targeted = attack_params['targeted']\n",
    "        if targeted == 'next':\n",
    "            Y_test_target = Y_test_target_next\n",
    "        elif targeted == 'll':\n",
    "            Y_test_target = Y_test_target_ll\n",
    "    else:\n",
    "        targeted = False\n",
    "        attack_params['targeted'] = False\n",
    "        Y_test_target = Y_test.copy()\n",
    "\n",
    "    x_adv_fname = \"%s_%s.pickle\" % (task_id, attack_string)\n",
    "    x_adv_fpath = os.path.join(X_adv_cache_folder, x_adv_fname)\n",
    "\n",
    "    X_test_adv, aux_info = maybe_generate_adv_examples(sess, model, x, y, X_test, Y_test_target, attack_name, attack_params, use_cache = x_adv_fpath, verbose=FLAGS.verbose, attack_log_fpath=attack_log_fpath)\n",
    "    X_test_adv_list.append(X_test_adv)\n",
    "\n",
    "    if isinstance(aux_info, float):\n",
    "        duration = aux_info\n",
    "    else:\n",
    "        print (aux_info)\n",
    "        duration = aux_info['duration']\n",
    "\n",
    "    dur_per_sample = duration / len(X_test_adv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From here on is my code\n",
    "    1. I've developed a class called intermediate_layers that can output intermediate layer outputs of a Keras CNN model, visualize them using matplotlib, and calculate cosine distances between the flattened outputs of a normal image and its adverserial counterpart. I can do this for the entire model prediction and I can do it per depth channel for a specific layer. \n",
    "    \n",
    "    2. The cosine distances for the entire model predictions are usually around 0.85, which is high and shows that the adverserial images are significantly different than the normal images. However, the individual depth channels for each layer have much smaller cosine distances, and the biggest I've seen was 0.26. \n",
    "    \n",
    "    3. I want to conduct a test of cosine distances for successful versus unsuccesful adverserial examples to see if there is any relationship there, but I am having trouble creating an Azure instance under the research account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        4160      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 5, 5, 128)         295040    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 1, 128)         409728    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 710,218\n",
      "Trainable params: 710,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class intermediate_layers(object):\n",
    "    def __init__(self, model, X_test, X_test_adv):\n",
    "        self.model = model\n",
    "        self.X_test = X_test\n",
    "        self.X_test_adv = X_test_adv\n",
    "        self.norm_predictions = model.predict(X_test)\n",
    "        self.adv_predictions = model.predict(X_test_adv)\n",
    "        \n",
    "    def get_nth_layer_output(self, n):\n",
    "        '''\n",
    "        Given just the layer, returns the raw numpy output of the model at a certain layer\n",
    "        '''\n",
    "        model = self.model\n",
    "        X_batch = self.X_test\n",
    "        \n",
    "        get_activations = K.function([model.layers[0].input, K.learning_phase()], [model.layers[n].output])\n",
    "        activations = get_activations([X_batch])\n",
    "        return activations\n",
    "    \n",
    "    def nth_layer_output(self, layer, index, depth_layer=0, success=True, display=True):\n",
    "        '''\n",
    "        Given a specific layer 'n' and an index, returns the cosine distance between the original image\n",
    "        and the corresponding adverserial example, and can display the images as matplotlib subplots if\n",
    "        required.\n",
    "        '''\n",
    "        model = self.model\n",
    "        X_test = self.X_test\n",
    "        X_test_adv = self.X_test_adv\n",
    "        \n",
    "        norm_output = self.get_nth_layer_output(layer)[0][index,:,:,depth_layer] ###Output at specified layer\n",
    "        adv_output = self.get_nth_layer_output(layer)[0][index,:,:,depth_layer] ###Adverserial output\n",
    "\n",
    "        norm_predict = model.predict(X_test)[index] ###Prediction of entire model\n",
    "        adv_predict = model.predict(X_test_adv)[index] ###Adverserial prediction\n",
    "\n",
    "        layer_cosine_distance = str(distance.cosine(norm_output.flatten(),adv_output.flatten()))\n",
    "        total_cosine_distance = str(distance.cosine(norm_predict.flatten(),adv_predict.flatten()))\n",
    "        \n",
    "        if(self.is_successful_example(index) == success):\n",
    "            if display:\n",
    "                f, ax = plt.subplots(2,2)\n",
    "\n",
    "                ax[0,0].imshow(X_test[index,:,:,0])\n",
    "                ax[0,1].imshow(norm_output)\n",
    "                ax[1,0].imshow(X_test_adv[index,:,:,0])\n",
    "                ax[1,1].imshow(adv_output)\n",
    "\n",
    "                ax[0,0].set_title(\"Normal Test Image\")\n",
    "                ax[0,1].set_title(\"Layer %s Output\"%str(layer))\n",
    "                ax[1,0].set_title(\"Adverserial Test Image\")\n",
    "                ax[1,1].set_title(\"Layer %s Output\"%str(layer))\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "                print(\"One hot vector for normal image: %s\"%norm_predict)\n",
    "                print(\"One hot vector for adverserial image: %s\"%adv_predict)\n",
    "                print(\"Layer Cosine Distance: %s\"%layer_cosine_distance)\n",
    "                print(\"Overall Cosine Distance: %s\"%total_cosine_distance)\n",
    "            return(layer_cosine_distance)\n",
    "        else:\n",
    "            return(np.NAN)\n",
    "            \n",
    "    def is_successful_example(self, index):\n",
    "        '''\n",
    "        Takes just an index value and returns a boolean detailing whether or not the test example\n",
    "        at that index is a succesful adverserial example\n",
    "        '''\n",
    "        model = self.model\n",
    "        X_test = self.X_test\n",
    "        X_test_adv = self.X_test_adv\n",
    "        norm_predict = model.predict(X_test)[index] ###Prediction of entire model\n",
    "        adv_predict = model.predict(X_test_adv)[index] ###Adverserial prediction\n",
    "        return(adv_predict.argmax()!=norm_predict.argmax())\n",
    "        \n",
    "    def disp_all_depth_intermediates(self, layer, indices=None, success=True):\n",
    "        '''\n",
    "        Displays all depth dimensions for the specified intermediate layer and X_train examples(indices)\n",
    "        '''\n",
    "        if indices is None:\n",
    "            indices = range(self.X_test.shape[0])\n",
    "        i=0\n",
    "        while True:\n",
    "            try:\n",
    "                list(map(lambda x: self.nth_layer_output(layer, x, i, success=success), indices))\n",
    "                i+=1\n",
    "            except:\n",
    "                break\n",
    "                \n",
    "    def total_cosine_distances(self, indices = None):\n",
    "        if indices is None:\n",
    "            indices = range(self.X_test.shape[0])\n",
    "            \n",
    "        norm_predictions = self.norm_predictions\n",
    "        adv_predictions = self.adv_predictions\n",
    "        distances = list(map(lambda x:str(distance.cosine(\n",
    "            norm_predictions[x].flatten(),adv_predictions[x].flatten())), indices))\n",
    "\n",
    "        return distances\n",
    "    \n",
    "    def layer_cosine_distances(self, layer, indices = None, display=False):\n",
    "        '''\n",
    "        returns the cosine distances between the normal layer output and the adverserial layer output for\n",
    "        succesful or unsuccesful adverserial examples\n",
    "        '''\n",
    "        if indices is None:\n",
    "            indices = range(self.X_test.shape[0])\n",
    "        i=0\n",
    "        distances = []\n",
    "        while True:\n",
    "            try:\n",
    "                distances.append(list(map(lambda x: self.nth_layer_output(layer, x, i, display=False), indices)))\n",
    "                i+=1\n",
    "            except:\n",
    "                break\n",
    "        total_cosine_distance = self.total_cosine_distances(indices)\n",
    "        values = zip(total_cosine_distance,list(map(self.is_successful_example,indices)),zip(*distances))\n",
    "        return(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = intermediate_layers(model, X_test, X_test_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = im.layer_cosine_distances(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = list(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.9387105e-09"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(list(distances[0][2]),dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Cosine Distance: 0.85205192991, Sum Layer Cosine Distance: -8.881549433681357e-07\n",
      "Overall Cosine Distance: 0.857820055304, Sum Layer Cosine Distance: -1.826022753448342e-06\n",
      "Overall Cosine Distance: 0.856905721642, Sum Layer Cosine Distance: -5.958978590570041e-07\n",
      "Overall Cosine Distance: 0.853775366735, Sum Layer Cosine Distance: 1.4540563597620348e-07\n",
      "Overall Cosine Distance: 0.852611685658, Sum Layer Cosine Distance: -4.09225947350933e-07\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119684d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_vals = []\n",
    "y_vals = []\n",
    "\n",
    "for example in list(distances):\n",
    "    x = float(np.sum(np.array(list(example[2]),dtype=np.float32)))\n",
    "    y = float(example[0])\n",
    "    x_vals.append(x)\n",
    "    y_vals.append(y)\n",
    "    print(\"Overall Cosine Distance: %s, Sum Layer Cosine Distance: %s\"%(y, x))\n",
    "\n",
    "plt.scatter(stats.zscore(np.array(x_vals)), stats.zscore(np.array(y_vals)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
